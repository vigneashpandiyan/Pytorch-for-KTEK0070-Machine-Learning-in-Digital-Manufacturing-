{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://vigneashpandiyan.github.io/publications/Codes/\" target=\"_blank\" rel=\"noopener noreferrer\">\n","  <img src=\"https://vigneashpandiyan.github.io/images/Link.png\"\n","       style=\"max-width: 800px; width: 100%; height: auto;\">\n","</a>"],"metadata":{"id":"lSdq9pyZsf7V"}},{"cell_type":"markdown","metadata":{"id":"aTOLgsbN69-P"},"source":["# Calculus II: Partial Derivatives & Integrals"]},{"cell_type":"markdown","metadata":{"id":"yqUB9FTRAxd-"},"source":[" *Calculus II: Partial Derivatives & Integrals*, builds on single-variable derivative calculus to introduce gradients and integral calculus. Gradients of learning, which are facilitated by partial-derivative calculus, are the basis of training most machine learning algorithms"]},{"cell_type":"markdown","metadata":{"id":"d4tBvI88BheF"},"source":["Over the course of studying this topic, you'll:\n","\n","* Develop an understanding of whatâ€™s going on beneath the hood of machine learning algorithms, including those used for deep learning.\n","* Be able to grasp the details of the partial-derivative, multivariate calculus that is common in machine learning papers as well as many in other subjects that underlie ML, including information theory and optimization algorithms.\n"]},{"cell_type":"markdown","metadata":{"id":"9v7wHzEaDoeT"},"source":["##  Gradients Applied to Machine Learning"]},{"cell_type":"code","metadata":{"id":"-09IzaDRDoeU"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import math # for constant pi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmonXg8-DoeV"},"source":["### Partial Derivatives of Multivariate Functions"]},{"cell_type":"markdown","metadata":{"id":"jt2Fb7bmDoeV"},"source":["Define a function $f(x, y)$ for $z = x^2 - y^2$:"]},{"cell_type":"code","metadata":{"id":"Xb_f6pUYDoeV"},"source":["def f(my_x, my_y):\n","    return my_x**2 - my_y**2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Yxx42_UDoeV"},"source":["Plot $z$ with respect to $x$ by varying $x$..."]},{"cell_type":"code","metadata":{"id":"Toba6LVQDoeW"},"source":["xs = np.linspace(-3, 3, 1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sazf_xu9DoeW"},"source":["...while holding $y$ constant (e.g., at $y = 0$):"]},{"cell_type":"code","metadata":{"id":"9Z31rNZvDoeW"},"source":["zs_wrt_x = f(xs, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdZ6Rdr4DoeX"},"source":["fig, ax = plt.subplots()\n","plt.axvline(x=0, color='lightgray')\n","plt.axhline(y=0, color='lightgray')\n","\n","plt.xlabel('x')\n","plt.ylabel('z', rotation=0)\n","_ = ax.plot(xs, zs_wrt_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TctSbA-VDoeY"},"source":["To determine the slope of $z$ w.r.t. $x$ at a given point along the curve, we can use the partial derivative : $$ \\frac{\\partial z}{\\partial x} = 2x$$"]},{"cell_type":"code","metadata":{"id":"WM2UTR4DDoeY"},"source":["def delz_delx(my_x, my_y): # y isn't relevant for *this* partial derivative; it often would be\n","    return 2*my_x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqarAEMODoeY"},"source":["x_samples = [-2, -1, 0, 1, 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExzFLbjODoeY"},"source":["colors = ['red', 'orange', 'green', 'blue', 'purple']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPeZ7Qf0DoeZ"},"source":["def point_and_tangent_wrt_x(my_xs, my_x, my_y, my_f, fprime, col):\n","\n","    my_z = my_f(my_x, my_y) # z = f(x, y)\n","    plt.scatter(my_x, my_z, c=col, zorder=3)\n","\n","    tangent_m = fprime(my_x, my_y) # Slope is partial derivative of f(x, y) w.r.t. x\n","    tangent_b = my_z - tangent_m*my_x # Line is z=mx+b, so b=z-mx\n","    tangent_line = tangent_m*my_xs + tangent_b\n","\n","    plt.plot(my_xs, tangent_line, c=col,\n","             linestyle='dashed', linewidth=0.7, zorder=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3O2HIInDoeZ"},"source":["fig, ax = plt.subplots()\n","plt.axvline(x=0, color='lightgray')\n","plt.axhline(y=0, color='lightgray')\n","\n","for i, x in enumerate(x_samples):\n","    point_and_tangent_wrt_x(xs, x, 0, f, delz_delx, colors[i])\n","\n","plt.ylim(-1, 9)\n","plt.xlabel('x')\n","plt.ylabel('z', rotation=0)\n","_ = ax.plot(xs, zs_wrt_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8IJZYZfDoeZ"},"source":["Thereby visually demonstrating $\\frac{\\partial z}{\\partial x} = 2x$.\n","\n","That is, the slope of $z$ along the $x$ axis is *twice* the $x$ value."]},{"cell_type":"markdown","metadata":{"id":"ZEVnit5gDoea"},"source":["Now let's plot $z$ with respect to $y$ by varying $y$..."]},{"cell_type":"code","metadata":{"id":"ZZF8285-Doea"},"source":["ys = np.linspace(-3, 3, 1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSzx8uhLDoea"},"source":["...while holding $x$ constant (e.g., at $x$ = 0):"]},{"cell_type":"code","metadata":{"id":"D7L4yZ1aDoeb"},"source":["zs_wrt_y = f(0, ys)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGNORzJCDoeb"},"source":["fig, ax = plt.subplots()\n","plt.axvline(x=0, color='lightgray')\n","plt.axhline(y=0, color='lightgray')\n","\n","plt.xlabel('y')\n","plt.ylabel('z', rotation=0)\n","_ = ax.plot(ys, zs_wrt_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yftPl60zDoeb"},"source":["The partial derivative of $z$ w.r.t $y$ happens to be independent of $x$ (just as we observed $x$ is independent of $y$ above), so while $z$ varies as a function of both $x$ and $y$, the slope of $z$ w.r.t $y$ is the same no matter what $x$ is: $$ \\frac{\\partial z}{\\partial y} = -2y $$"]},{"cell_type":"markdown","metadata":{"id":"xX3gAdyWDoec"},"source":["So for example, holding $x$ constant at 2 instead of 0 increases $z$, but has no impact whatsoever on the slope of $z$ w.r.t. $y$:"]},{"cell_type":"code","metadata":{"id":"sdaSBdlrDoec"},"source":["zs_wrt_y = f(2, ys)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PW49KD7Doec"},"source":["fig, ax = plt.subplots()\n","plt.axvline(x=0, color='lightgray')\n","plt.axhline(y=0, color='lightgray')\n","\n","plt.xlabel('y')\n","plt.ylabel('z', rotation=0)\n","_ = ax.plot(ys, zs_wrt_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8vMax3uODoec"},"source":["def delz_dely(my_x, my_y):\n","    return -2*my_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkQ4GQyBDoed"},"source":["y_samples = [-2, -1, 0, 1, 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxsR448zDoed"},"source":["def point_and_tangent_wrt_y(my_ys, my_x, my_y, my_f, fprime, col): # changed my_xs to my_ys\n","\n","    my_z = my_f(my_x, my_y)\n","    plt.scatter(my_y, my_z, c=col, zorder=3) # changed my_x to my_y\n","\n","    tangent_m = fprime(my_x, my_y)\n","    tangent_b = my_z - tangent_m*my_y # changed my_x to my_y\n","    tangent_line = tangent_m*my_ys + tangent_b # changed my_xs to my_ys\n","\n","    plt.plot(my_ys, tangent_line, c=col,\n","             linestyle='dashed', linewidth=0.7, zorder=3) # changed my_xs to my_ys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8EXlci4Doed"},"source":["fig, ax = plt.subplots()\n","plt.axvline(x=0, color='lightgray')\n","plt.axhline(y=0, color='lightgray')\n","\n","for i, y in enumerate(y_samples):\n","    point_and_tangent_wrt_y(ys, 2, y, f, delz_dely, colors[i])\n","\n","plt.ylim(-5, 5)\n","plt.xlabel('y')\n","plt.ylabel('z', rotation=0)\n","_ = ax.plot(xs, zs_wrt_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZV2FTIU66UG-"},"source":["Thereby visually demonstrating $\\frac{\\partial z}{\\partial y} = -2y$.\n","\n","That is, the slope of $z$ along the $y$ axis is *twice* the $y$ value *and inverted*, resulting in the parabolic curve opening downward."]},{"cell_type":"markdown","metadata":{"id":"V7P12cWuDoef"},"source":["**Exercises**: Use pencil and paper to determine:\n","\n","* The value of $z$,\n","* The slope of $z$ with respect to $x$,\n","* And the slope of $z$ with respect to $y$\n","\n","...at the points where:\n","\n","1. $x = 3, y = 0$\n","2. $x = 2, y = 3$\n","3. $x = -2, y = -3$"]},{"cell_type":"markdown","metadata":{"id":"IwiI0uisDoeg"},"source":["Determining partial derivatives by hand using rules is helpful for understanding how calculus works. In practice, however, autodiff enables us to do so more easily (especially if there are a large number of variables). For example, let's use the PyTorch automatic differentiation library to calculate the slope of $z$ with respect to both $x$ and $y$ at any given point $(x, y, z)$:"]},{"cell_type":"code","metadata":{"id":"SHeFsRfrDoeg"},"source":["x = torch.tensor(0.).requires_grad_()\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzWjTchwDoeg"},"source":["y = torch.tensor(0.).requires_grad_()\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7TprOE-Doeh"},"source":["z = f(x, y) # Forward pass\n","z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyefZb67Doeh"},"source":["z.backward() # Autodiff"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_L7fUeBfDoeh"},"source":["As we already knew from our exercises above, the slope of the point (0, 0, 0) is zero with respect to both the $x$ and $y$ axes:"]},{"cell_type":"code","metadata":{"id":"VCX2ngT9Doeh"},"source":["x.grad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DeU2IYODoei"},"source":["y.grad"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eblx3YW6Doei"},"source":["**Exercise**: Repeat the most recent pencil-and-paper exercises using PyTorch (or TensorFlow, if you prefer)."]},{"cell_type":"markdown","metadata":{"id":"3NqDfYGeDoej"},"source":["### Partial Derivatives of a Cylinder's Volume"]},{"cell_type":"markdown","metadata":{"id":"8zOAmeOnDoej"},"source":["The volume of a cylinder is described by $v = \\pi r^2 l$ where:\n","\n","* $r$ is the radius of the cylinder\n","* $l$ is its length"]},{"cell_type":"code","metadata":{"id":"Y345YQ2iDoej"},"source":["def cylinder_vol(my_r, my_l):\n","    return math.pi * my_r**2 * my_l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eGolCTLDoej"},"source":["# Let's say the radius is 3 meters...\n","r = torch.tensor(3.).requires_grad_()\n","r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sp3kUgQ6Doej"},"source":["# ...and length is 5 meters:\n","l = torch.tensor(5.).requires_grad_()\n","l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FBBkAM6Doek"},"source":["# Then the volume of the cylinder is 141.4 cubic meters:\n","v = cylinder_vol(r, l)\n","v"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iGlPQyjDoek"},"source":["v.backward()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvIA09YGDoek"},"source":["l.grad"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TYD2k4J3Doel"},"source":[" $$\\frac{\\partial v}{\\partial l} = \\pi r^2$$"]},{"cell_type":"code","metadata":{"id":"q6YRwpMvDoel"},"source":["math.pi * 3**2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UavsjoQFDoel"},"source":["This means that with $r = 3$, a change in $l$ by one unit corresponds to a change in $v$ of 28.27$\\text{m}^3$. We can prove this to ourselves:"]},{"cell_type":"code","metadata":{"id":"H32PplygDoel"},"source":["cylinder_vol(3, 6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmwxrip1Doem"},"source":["cylinder_vol(3, 6) - cylinder_vol(3, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGuDzwwxDoem"},"source":["cylinder_vol(3, 7) - cylinder_vol(3, 6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yC4GJ8iZDoem"},"source":["For changes in $v$ with respect to $r$ we have : $$\\frac{\\partial v}{\\partial r} = 2 \\pi r l$$"]},{"cell_type":"code","metadata":{"id":"cAVbIBiCDoen"},"source":["r.grad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UzHESN6XDoen"},"source":["2 * math.pi * 3 * 5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lWzx4YxuDoen"},"source":["$r$ is included in the partial derivative so adjusting it affects the scale of its impact on $v$. Although it's our first example in this notebook, it is typical in calculus for the derivative only to apply at an infinitesimally small $\\Delta r$. The smaller the $\\Delta r$, the closer to the true $\\frac{\\partial v}{\\partial r}$. E.g., at $\\Delta r = 1 \\times 10^{-6}$:"]},{"cell_type":"code","metadata":{"id":"JN0waPUmDoen"},"source":["delta = 1e-6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCk5RPL8Doeo"},"source":["(cylinder_vol(3 + delta, 5) - cylinder_vol(3, 5)) / delta # Dividing by delta restores scale"],"execution_count":null,"outputs":[]}]}