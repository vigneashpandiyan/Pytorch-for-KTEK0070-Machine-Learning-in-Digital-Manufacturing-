{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOSp8kWBBNXcog0lYS1cw7X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://vigneashpandiyan.github.io/publications/Codes/\" target=\"_blank\" rel=\"noopener noreferrer\">\n","  <img src=\"https://vigneashpandiyan.github.io/images/Link.png\"\n","       style=\"max-width: 800px; width: 100%; height: auto;\">\n","</a>"],"metadata":{"id":"yR-bi_MUR8nE"}},{"cell_type":"markdown","source":["### Data Cleaning\n","\n","Data cleaning is the process of correcting or removing inaccurate, incomplete, duplicate, or irrelevant data from the dataset. It is a crucial step in data analysis and machine learning because clean data ensures more accurate results, meaningful insights and reliable models. Common tasks include handling missing values, fixing formatting issues, and removing duplicates.\n","\n","The below dataset will be used for the next few blocks. At any point, it can be executed again to reset the dataset."],"metadata":{"id":"gAtdzFhdaZ4K"}},{"cell_type":"code","source":["# @title\n","import pandas as pd\n","\n","data = [\n","    [60, '2020/12/01', 110, 130, 409.1],\n","    [60, '2020/12/02', 117, 145, 479.0],\n","    [60, '2020/12/03', 103, 135, 340.0],\n","    [45, '2020/12/04', 109, 175, 282.4],\n","    [45, '2020/12/05', 117, 148, 406.0],\n","    [60, '2020/12/06', 102, 127, 300.0],\n","    [60, '2020/12/07', 110, 136, 374.0],\n","    [40, '2020/12/08', 104, 134, 253.3],\n","    [30, '2020/12/09', 109, 133, 195.1],\n","    [60, '2020/12/10', 98, 124, 269.0],\n","    [60, '2020/12/11', 103, 147, 329.3],\n","    [60, '2020/12/12', 100, 120, 250.7],\n","    [60, '2020/12/12', 100, 120, 250.7],\n","    [60, '2020/12/13', 106, 128, 345.3],\n","    [60, '2020/12/14', 104, 132, 379.3],\n","    [60, '2020/12/15', 98, 123, 275.0],\n","    [60, '2020/12/16', 98, 120, 215.2],\n","    [60, '2020/12/17', 100, 120, 300.0],\n","    [45, '2020/12/18', 90, 112, None],\n","    [60, '2020/12/19', 103, 123, 323.0],\n","    [45, '2020/12/20', 97, 125, 243.0],\n","    [60, '2020/12/21', 108, 131, 364.2],\n","    [45, None, 100, 119, 282.0],\n","    [60, '2020/12/23', 130, 101, 300.0],\n","    [45, '2020/12/24', 105, 132, 246.0],\n","    [60, '2020/12/25', 102, 126, 334.5],\n","    [60, '2020/12/26', 100, 120, 250.0],\n","    [60, '2020/12/27', 92, 118, 241.0],\n","    [60, '2020/12/28', 103, 132, None],\n","    [60, '2020/12/29', 100, 132, 280.0],\n","    [60, '2020/12/30', 102, 129, 380.3],\n","    [60, '2020/12/31', 92, 115, 243.0]\n","]\n","\n","columns = [\"Duration\", \"Date\", \"Pulse\", \"Maxpulse\", \"Calories\"]\n","df = pd.DataFrame(data, columns=columns)\n","df.to_csv(\"calories.csv\", index=False)\n"],"metadata":{"id":"-BJk9t-VamwZ","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" print(df.info())"],"metadata":{"id":"wUwZYhVFbE5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.to_string())"],"metadata":{"id":"zq4R47YXv8BW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The data set contains some empty cells (\"Date\" in row 22, and \"Calories\" in row 18 and 28).\n","\n","The data set contains duplicates (row 11 and 12)."],"metadata":{"id":"EvNDc0msvkFZ"}},{"cell_type":"markdown","source":["### Missing Data\n","Empty cells can potentially give a wrong result when the data is analyzed.\n","One way to deal with missing data is to remove simply remove rows that contain empty cells. This is usually fine for  large data sets as removing a few rows will not have a big impact on the result."],"metadata":{"id":"Ru-dRFND-ASH"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('calories.csv')\n","\n","new_df = df.dropna() #Remove rows with empty cells\n","\n","print(new_df.to_string())"],"metadata":{"id":"EFRK3eph9_s_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note this is a new dataFrame, which leaves the original file unmodified.\n","By using:\n","\n","> df.dropna(inplace = True)\n","\n",", the original dataFrame may be modified."],"metadata":{"id":"fBJbHavZAoIm"}},{"cell_type":"markdown","source":["Another way of dealing with empty cells is to insert a new value instead. This is termed as data imputation, wherein missing values in a dataset are replaced with estimated values. One way involves replacing any missing value with the mean of that variable for all other cases, which has the benefit of not changing the sample mean for that variable. Other statistical quantities may also be used."],"metadata":{"id":"b_yUqXGsCAK_"}},{"cell_type":"markdown","source":["The fillna() method replaces empty cells with a single value. This may be a precalculated mean, mode or median.\n"],"metadata":{"id":"qJ9pLvZqDAmJ"}},{"cell_type":"code","source":["x = df[\"Calories\"].mean()\n","new_df = df.fillna(x) #Replace missing data with mean of Calories\n","\n","print(new_df.to_string())"],"metadata":{"id":"gAr3SXb_C_E8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hoever, note that the above method also replaced the missing date too!\n","To only replace empty values for one column, the column name may be specified:\n"],"metadata":{"id":"fuT6SpdjD852"}},{"cell_type":"code","source":["x = df[\"Calories\"].median()\n","new_df = df.fillna({\"Calories\": x}) #Replace with mode of calories\n","print(new_df.to_string())"],"metadata":{"id":"BLekod3GLpvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lastly, it makes sense to find out any duplicated records in the dataset.\n","The duplicated() method returns a Boolean values for each row where data is repeated."],"metadata":{"id":"9T9YIXYGNE25"}},{"cell_type":"code","source":[" print(new_df.duplicated())"],"metadata":{"id":"Rw2xGSygNCvN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And finally, to remove all duplicates:"],"metadata":{"id":"W6S_O_U4NpzY"}},{"cell_type":"code","source":[" new_df.drop_duplicates(inplace = True) #inplace paramter will modify the dataframe\n"," print(new_df.to_string())"],"metadata":{"id":"RWZKnu52Ntm3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Filtering\n","\n"," Filtering the dataset allows to extract specific rows based on conditions applied to one or more columns, making it easier to work with relevant subsets of data."],"metadata":{"id":"1UGl17SyOMLd"}},{"cell_type":"code","source":["filtered_df = new_df.loc[new_df['Pulse'] > 99, ['Maxpulse', 'Calories']]\n","print(filtered_df)"],"metadata":{"id":"e6PguFNcOvVh"},"execution_count":null,"outputs":[]}]}